Mon May 17 16:56:45 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA Quadro R...  On   | 00000000:B1:00.0 Off |                  Off |
| 50%   63C    P8    24W / 260W |      3MiB / 24220MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
Collecting nltk
  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)
Collecting matplotlib
  Downloading matplotlib-3.4.2-cp38-cp38-manylinux1_x86_64.whl (10.3 MB)
Collecting beautifulsoup4
  Downloading beautifulsoup4-4.9.3-py3-none-any.whl (115 kB)
Collecting torch==1.7.1
  Downloading torch-1.7.1-cp38-cp38-manylinux1_x86_64.whl (776.8 MB)
Collecting torchtext==0.8
  Downloading torchtext-0.8.0-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)
Collecting joblib
  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)
Collecting regex
  Downloading regex-2021.4.4-cp38-cp38-manylinux2014_x86_64.whl (733 kB)
Requirement already satisfied: tqdm in /home/user/miniconda/lib/python3.8/site-packages (from nltk->-r requirements.txt (line 1)) (4.46.0)
Collecting click
  Downloading click-8.0.0-py3-none-any.whl (96 kB)
Collecting pyparsing>=2.2.1
  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)
Collecting kiwisolver>=1.0.1
  Downloading kiwisolver-1.3.1-cp38-cp38-manylinux1_x86_64.whl (1.2 MB)
Collecting python-dateutil>=2.7
  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)
Requirement already satisfied: numpy>=1.16 in /home/user/miniconda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 2)) (1.19.2)
Requirement already satisfied: pillow>=6.2.0 in /home/user/miniconda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 2)) (8.2.0)
Collecting cycler>=0.10
  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)
Collecting soupsieve>1.2; python_version >= "3.0"
  Downloading soupsieve-2.2.1-py3-none-any.whl (33 kB)
Requirement already satisfied: typing-extensions in /home/user/miniconda/lib/python3.8/site-packages (from torch==1.7.1->-r requirements.txt (line 4)) (3.7.4.3)
Requirement already satisfied: requests in /home/user/miniconda/lib/python3.8/site-packages (from torchtext==0.8->-r requirements.txt (line 5)) (2.23.0)
Requirement already satisfied: six>=1.5 in /home/user/miniconda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 2)) (1.14.0)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/user/miniconda/lib/python3.8/site-packages (from requests->torchtext==0.8->-r requirements.txt (line 5)) (1.25.8)
Requirement already satisfied: certifi>=2017.4.17 in /home/user/miniconda/lib/python3.8/site-packages (from requests->torchtext==0.8->-r requirements.txt (line 5)) (2020.12.5)
Requirement already satisfied: idna<3,>=2.5 in /home/user/miniconda/lib/python3.8/site-packages (from requests->torchtext==0.8->-r requirements.txt (line 5)) (2.9)
Requirement already satisfied: chardet<4,>=3.0.2 in /home/user/miniconda/lib/python3.8/site-packages (from requests->torchtext==0.8->-r requirements.txt (line 5)) (3.0.4)
Installing collected packages: joblib, regex, click, nltk, pyparsing, kiwisolver, python-dateutil, cycler, matplotlib, soupsieve, beautifulsoup4, torch, torchtext
  Attempting uninstall: torch
    Found existing installation: torch 1.8.1
    Uninstalling torch-1.8.1:
      Successfully uninstalled torch-1.8.1
Successfully installed beautifulsoup4-4.9.3 click-8.0.0 cycler-0.10.0 joblib-1.0.1 kiwisolver-1.3.1 matplotlib-3.4.2 nltk-3.6.2 pyparsing-2.4.7 python-dateutil-2.8.1 regex-2021.4.4 soupsieve-2.2.1 torch-1.7.1 torchtext-0.8.0
./artifacts//LMdata_wikitext-2.pkl
Loading dataset from ./artifacts//LMdata_wikitext-2.pkl
loaded
Loaded LMbenchmark: 28903 words, 0 QA
28903
{'test': None, 'createDataset': True, 'playDataset': 10, 'reset': True, 'device': 'cuda:0', 'rootDir': './artifacts/', 'retrain_model': 'No', 'maxLength': 100, 'vocabularySize': 28903, 'hiddenSize': 100, 'numLayers': 6, 'softmaxSamples': 0, 'initEmbeddings': True, 'embeddingSize': 300, 'numEpochs': 1000, 'saveEvery': 2000, 'batchSize': 64, 'learningRate': 0.001, 'dropout': 0.9, 'clip': 5.0, 'encunit': 'lstm', 'decunit': 'lstm', 'enc_numlayer': 2, 'dec_numlayer': 2, 'maxLengthEnco': 100, 'maxLengthDeco': 101, 'temperature': 1.0, 'LMtype': 'energy', 'corpus': 'wiki2', 'server': 'dgx', 'nhead': 4, 'choose': 'BET-nadm', 'norm_attn': True}
LanguageModel creation...
33586553 134.356964 m
<class 'dict'> cuda:0
23627
niters  370
2870
perplexity =  115.67453270199047 >= min_perplexity ( -1 ), saving model...
Epoch  0 loss =  3.9412790630314802 Valid perplexity =  115.67453270199047
perplexity =  96.43536181819287 >= min_perplexity ( 115.67453270199047 ), saving model...
Epoch  1 loss =  3.615607471884908 Valid perplexity =  96.43536181819287
perplexity =  85.57956255043725 >= min_perplexity ( 96.43536181819287 ), saving model...
Epoch  2 loss =  3.495703990717192 Valid perplexity =  85.57956255043725
perplexity =  79.58821572640494 >= min_perplexity ( 85.57956255043725 ), saving model...
Epoch  3 loss =  3.405150296075924 Valid perplexity =  79.58821572640494
perplexity =  76.34828858318383 >= min_perplexity ( 79.58821572640494 ), saving model...
Epoch  4 loss =  3.333964590446369 Valid perplexity =  76.34828858318383
perplexity =  72.8973127586876 >= min_perplexity ( 76.34828858318383 ), saving model...
Epoch  5 loss =  3.273367543800457 Valid perplexity =  72.8973127586876
perplexity =  71.06510559162206 >= min_perplexity ( 72.8973127586876 ), saving model...
Epoch  6 loss =  3.219352246941747 Valid perplexity =  71.06510559162206
perplexity =  69.61494687506037 >= min_perplexity ( 71.06510559162206 ), saving model...
Epoch  7 loss =  3.170161408991427 Valid perplexity =  69.61494687506037
perplexity =  68.53436815757328 >= min_perplexity ( 69.61494687506037 ), saving model...
Epoch  8 loss =  3.126536512697065 Valid perplexity =  68.53436815757328
perplexity =  67.26535119796421 >= min_perplexity ( 68.53436815757328 ), saving model...
Epoch  9 loss =  3.0848231135187922 Valid perplexity =  67.26535119796421
perplexity =  66.90692041928281 >= min_perplexity ( 67.26535119796421 ), saving model...
Epoch  10 loss =  3.0445348288561846 Valid perplexity =  66.90692041928281
perplexity =  66.5145150984824 >= min_perplexity ( 66.90692041928281 ), saving model...
Epoch  11 loss =  3.003816720762768 Valid perplexity =  66.5145150984824
perplexity =  65.04707753515534 >= min_perplexity ( 66.5145150984824 ), saving model...
Epoch  12 loss =  2.9645221905128376 Valid perplexity =  65.04707753515534
Epoch  13 loss =  2.929575247055775 Valid perplexity =  65.31842091116808
perplexity =  64.36884680072893 >= min_perplexity ( 65.04707753515534 ), saving model...
Epoch  14 loss =  2.8937249488121752 Valid perplexity =  64.36884680072893
perplexity =  64.00731945653949 >= min_perplexity ( 64.36884680072893 ), saving model...
Epoch  15 loss =  2.859605134177852 Valid perplexity =  64.00731945653949
perplexity =  61.04907869903284 >= min_perplexity ( 64.00731945653949 ), saving model...
Epoch  16 loss =  2.825245888329841 Valid perplexity =  61.04907869903284
perplexity =  60.74214801740741 >= min_perplexity ( 61.04907869903284 ), saving model...
Epoch  17 loss =  2.793302174516626 Valid perplexity =  60.74214801740741
Epoch  18 loss =  2.7601524749317683 Valid perplexity =  61.909741250982805
perplexity =  59.663132957545265 >= min_perplexity ( 60.74214801740741 ), saving model...
Epoch  19 loss =  2.730641121960975 Valid perplexity =  59.663132957545265
perplexity =  59.63953449043572 >= min_perplexity ( 59.663132957545265 ), saving model...
Epoch  20 loss =  2.6979917315212454 Valid perplexity =  59.63953449043572
perplexity =  59.232945145775155 >= min_perplexity ( 59.63953449043572 ), saving model...
Epoch  21 loss =  2.670847069894945 Valid perplexity =  59.232945145775155
Epoch  22 loss =  2.638954405687951 Valid perplexity =  59.49848247342747
perplexity =  57.578359134610125 >= min_perplexity ( 59.232945145775155 ), saving model...
Epoch  23 loss =  2.6097154593145526 Valid perplexity =  57.578359134610125
Epoch  24 loss =  2.5810630418158866 Valid perplexity =  60.26305307474644
Epoch  25 loss =  2.553627285925118 Valid perplexity =  58.78142525392051
Epoch  26 loss =  2.5258489020772883 Valid perplexity =  60.57663283963464
36m 53s (- 2021-05-17 17:34:52.817374) (10000 2702%) loss = 2.9900, CE_loss = 2.9900, VAE recon = 0.0000, KL = 0.0000, error=0.0000
Test ppl:  53.498154460973126
perplexity =  53.498154460973126 >= min_perplexity ( 57.578359134610125 ), saving model...
Epoch  27 loss =  2.49798050732226 Valid perplexity =  58.432513994876956
Epoch  28 loss =  2.47185457236058 Valid perplexity =  60.39959182275636
Epoch  29 loss =  2.4460233027870593 Valid perplexity =  58.77869701468904
Epoch  30 loss =  2.4177651977216876 Valid perplexity =  59.5825499621719
Epoch  31 loss =  2.394401587666692 Valid perplexity =  58.40632580984766
Epoch  32 loss =  2.370708863155262 Valid perplexity =  57.476189454963595
Epoch  33 loss =  2.3474831139719163 Valid perplexity =  59.0498251499926
Epoch  34 loss =  2.3239854095755397 Valid perplexity =  59.811657652549265
Epoch  35 loss =  2.2974267025251645 Valid perplexity =  59.13715351799294
Epoch  36 loss =  2.273652376194258 Valid perplexity =  60.74723202746063
Epoch  37 loss =  2.246815141310563 Valid perplexity =  63.74122740898483
Epoch  38 loss =  2.225447929388768 Valid perplexity =  61.78139867372304
Epoch  39 loss =  2.2041284147146585 Valid perplexity =  62.974173617206276
Epoch  40 loss =  2.1797213050159248 Valid perplexity =  62.10088921527228
Epoch  41 loss =  2.155185608928268 Valid perplexity =  63.73918935785449
Epoch  42 loss =  2.128856253785056 Valid perplexity =  65.06759832939093
Epoch  43 loss =  2.1089178254475467 Valid perplexity =  64.13895240372591
Epoch  44 loss =  2.087994281987886 Valid perplexity =  66.44877124419209
Epoch  45 loss =  2.0728743897902 Valid perplexity =  66.42703858954633
Epoch  46 loss =  2.04568925097182 Valid perplexity =  67.48705324497708
Epoch  47 loss =  2.0260032330010387 Valid perplexity =  67.48254823819191
Epoch  48 loss =  2.0012757338382103 Valid perplexity =  68.14884372116559
Epoch  49 loss =  1.9811499541675723 Valid perplexity =  70.06604787947397
Epoch  50 loss =  1.9625586423519494 Valid perplexity =  69.77142087267255
Epoch  51 loss =  1.9398461680154542 Valid perplexity =  71.19605483611268
Epoch  52 loss =  1.9206385200893556 Valid perplexity =  71.60165441199649
Epoch  53 loss =  1.9040137177383578 Valid perplexity =  74.14399306252643
73m 46s (- 2021-05-17 18:11:45.682931) (20000 5405%) loss = 2.1857, CE_loss = 2.1857, VAE recon = 0.0000, KL = 0.0000, error=0.0000
Test ppl:  69.61377138896653
Epoch  54 loss =  1.888672265893704 Valid perplexity =  73.23494642036242
Epoch  55 loss =  1.872134649109196 Valid perplexity =  73.67274394945659
Epoch  56 loss =  1.8493484878862225 Valid perplexity =  76.28263008926794
Epoch  57 loss =  1.828937904818638 Valid perplexity =  78.69996743723908
Epoch  58 loss =  1.8134084840078613 Valid perplexity =  79.29541318979999
Epoch  59 loss =  1.7959936198350546 Valid perplexity =  79.80544976839984
Epoch  60 loss =  1.7821513893636498 Valid perplexity =  81.53467711277013
Epoch  61 loss =  1.770607448751862 Valid perplexity =  82.77689109621087
Epoch  62 loss =  1.7536733669203681 Valid perplexity =  81.53220018029282
Epoch  63 loss =  1.7321997002169893 Valid perplexity =  85.65823212457494
Epoch  64 loss =  1.719217154061472 Valid perplexity =  83.66525753342465
Epoch  65 loss =  1.7056440131084338 Valid perplexity =  88.10072888152807
Epoch  66 loss =  1.6920217107276658 Valid perplexity =  89.37331556177641
Epoch  67 loss =  1.6787581004001 Valid perplexity =  92.84405577900056
Epoch  68 loss =  1.6691230282590197 Valid perplexity =  93.68904983716833
Epoch  69 loss =  1.6531349847445618 Valid perplexity =  95.33966317583791
Epoch  70 loss =  1.6384233206510543 Valid perplexity =  99.57662172234663
Epoch  71 loss =  1.6219945391287676 Valid perplexity =  97.67046687290153
Epoch  72 loss =  1.6067693729658385 Valid perplexity =  99.49934983897893
Epoch  73 loss =  1.5940280469688208 Valid perplexity =  104.9085426050759
Epoch  74 loss =  1.5863201101889481 Valid perplexity =  107.45505986955861
Epoch  75 loss =  1.5751775641699095 Valid perplexity =  103.49313328155306
Epoch  76 loss =  1.5593597240544654 Valid perplexity =  106.52375188290267
Epoch  77 loss =  1.5497763719913122 Valid perplexity =  106.63843367600876
Epoch  78 loss =  1.5346806911197868 Valid perplexity =  108.61844407163832
Epoch  79 loss =  1.5238524983058104 Valid perplexity =  110.24648272853953
Epoch  80 loss =  1.5101193474756704 Valid perplexity =  113.07332465471266
110m 37s (- 2021-05-17 18:48:36.801233) (30000 8108%) loss = 1.6843, CE_loss = 1.6843, VAE recon = 0.0000, KL = 0.0000, error=0.0000
Test ppl:  98.3808625022324
Epoch  81 loss =  1.500231072226086 Valid perplexity =  112.27647765555827
Epoch  82 loss =  1.4879786049192016 Valid perplexity =  120.48267145183672
Epoch  83 loss =  1.47968953952596 Valid perplexity =  112.58472081686688
Epoch  84 loss =  1.4711591080233857 Valid perplexity =  115.21920245848762
Epoch  85 loss =  1.460264976926752 Valid perplexity =  119.12354650335976
Epoch  86 loss =  1.4512682227669536 Valid perplexity =  120.28840670775026
Epoch  87 loss =  1.4479027812545364 Valid perplexity =  118.1788815664611
Epoch  88 loss =  1.4386002467290775 Valid perplexity =  122.13970202984349
Epoch  89 loss =  1.429759823148315 Valid perplexity =  120.98555536146422
Epoch  90 loss =  1.4255276761344962 Valid perplexity =  123.84459694603973
Epoch  91 loss =  1.4135474062449223 Valid perplexity =  124.84929787386977
Epoch  92 loss =  1.4045805720864115 Valid perplexity =  122.95722227619888
Epoch  93 loss =  1.391807808586069 Valid perplexity =  127.83964693135907
Epoch  94 loss =  1.3843568932365726 Valid perplexity =  130.08152953839664
Epoch  95 loss =  1.376905449499955 Valid perplexity =  131.5797099947712
Epoch  96 loss =  1.369121905436387 Valid perplexity =  130.7169496440595
Epoch  97 loss =  1.3608440033487372 Valid perplexity =  132.02482948216448
Epoch  98 loss =  1.3545966653405008 Valid perplexity =  131.32579621461682
Epoch  99 loss =  1.347466752255285 Valid perplexity =  133.2892901700727
Epoch  100 loss =  1.3443163867737795 Valid perplexity =  136.20269125882342
Epoch  101 loss =  1.3407075525941075 Valid perplexity =  137.1442671480684
Epoch  102 loss =  1.3405252016879416 Valid perplexity =  137.86304636301082
Epoch  103 loss =  1.3330521555365742 Valid perplexity =  139.0408815200126
Epoch  104 loss =  1.3243552106457788 Valid perplexity =  138.87530501711015
Epoch  105 loss =  1.3164834032187591 Valid perplexity =  139.7297315829564
Epoch  106 loss =  1.309575820935739 Valid perplexity =  141.22934851950296
Epoch  107 loss =  1.2973077132089719 Valid perplexity =  143.32716156876901
147m 38s (- 2021-05-17 19:25:38.222059) (40000 10810%) loss = 1.3919, CE_loss = 1.3919, VAE recon = 0.0000, KL = 0.0000, error=0.0000
Test ppl:  134.4714262177723
Epoch  108 loss =  1.2871391279471887 Valid perplexity =  147.26715405224851
Epoch  109 loss =  1.2794012938802306 Valid perplexity =  148.9486437903097
Epoch  110 loss =  1.2714708022974632 Valid perplexity =  151.43504723084314
Epoch  111 loss =  1.2638017385392575 Valid perplexity =  155.78945312278947
Epoch  112 loss =  1.2560261239876618 Valid perplexity =  155.3757020875131
Epoch  113 loss =  1.2505158361550923 Valid perplexity =  158.76948827809824
Epoch  114 loss =  1.2427459973741222 Valid perplexity =  155.96958344416544
