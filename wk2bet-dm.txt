Mon May 17 16:29:36 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |
| N/A   42C    P0    46W / 300W |      3MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
Collecting nltk
  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)
Collecting matplotlib
  Downloading matplotlib-3.4.2-cp38-cp38-manylinux1_x86_64.whl (10.3 MB)
Collecting beautifulsoup4
  Downloading beautifulsoup4-4.9.3-py3-none-any.whl (115 kB)
Collecting torch==1.7.1
  Downloading torch-1.7.1-cp38-cp38-manylinux1_x86_64.whl (776.8 MB)
Collecting torchtext==0.8
  Downloading torchtext-0.8.0-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)
Requirement already satisfied: tqdm in /home/user/miniconda/lib/python3.8/site-packages (from nltk->-r requirements.txt (line 1)) (4.46.0)
Collecting regex
  Downloading regex-2021.4.4-cp38-cp38-manylinux2014_x86_64.whl (733 kB)
Collecting click
  Downloading click-8.0.0-py3-none-any.whl (96 kB)
Collecting joblib
  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)
Collecting kiwisolver>=1.0.1
  Downloading kiwisolver-1.3.1-cp38-cp38-manylinux1_x86_64.whl (1.2 MB)
Requirement already satisfied: numpy>=1.16 in /home/user/miniconda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 2)) (1.19.2)
Requirement already satisfied: pillow>=6.2.0 in /home/user/miniconda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 2)) (8.2.0)
Collecting pyparsing>=2.2.1
  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)
Collecting cycler>=0.10
  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)
Collecting python-dateutil>=2.7
  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)
Collecting soupsieve>1.2; python_version >= "3.0"
  Downloading soupsieve-2.2.1-py3-none-any.whl (33 kB)
Requirement already satisfied: typing-extensions in /home/user/miniconda/lib/python3.8/site-packages (from torch==1.7.1->-r requirements.txt (line 4)) (3.7.4.3)
Requirement already satisfied: requests in /home/user/miniconda/lib/python3.8/site-packages (from torchtext==0.8->-r requirements.txt (line 5)) (2.23.0)
Requirement already satisfied: six in /home/user/miniconda/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->-r requirements.txt (line 2)) (1.14.0)
Requirement already satisfied: chardet<4,>=3.0.2 in /home/user/miniconda/lib/python3.8/site-packages (from requests->torchtext==0.8->-r requirements.txt (line 5)) (3.0.4)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/user/miniconda/lib/python3.8/site-packages (from requests->torchtext==0.8->-r requirements.txt (line 5)) (1.25.8)
Requirement already satisfied: idna<3,>=2.5 in /home/user/miniconda/lib/python3.8/site-packages (from requests->torchtext==0.8->-r requirements.txt (line 5)) (2.9)
Requirement already satisfied: certifi>=2017.4.17 in /home/user/miniconda/lib/python3.8/site-packages (from requests->torchtext==0.8->-r requirements.txt (line 5)) (2020.12.5)
Installing collected packages: regex, click, joblib, nltk, kiwisolver, pyparsing, cycler, python-dateutil, matplotlib, soupsieve, beautifulsoup4, torch, torchtext
  Attempting uninstall: torch
    Found existing installation: torch 1.8.1
    Uninstalling torch-1.8.1:
      Successfully uninstalled torch-1.8.1
Successfully installed beautifulsoup4-4.9.3 click-8.0.0 cycler-0.10.0 joblib-1.0.1 kiwisolver-1.3.1 matplotlib-3.4.2 nltk-3.6.2 pyparsing-2.4.7 python-dateutil-2.8.1 regex-2021.4.4 soupsieve-2.2.1 torch-1.7.1 torchtext-0.8.0
./artifacts//LMdata_wikitext-2.pkl
Loading dataset from ./artifacts//LMdata_wikitext-2.pkl
loaded
Loaded LMbenchmark: 28903 words, 0 QA
28903
{'test': None, 'createDataset': True, 'playDataset': 10, 'reset': True, 'device': 'cuda:0', 'rootDir': './artifacts/', 'retrain_model': 'No', 'maxLength': 100, 'vocabularySize': 28903, 'hiddenSize': 100, 'numLayers': 6, 'softmaxSamples': 0, 'initEmbeddings': True, 'embeddingSize': 300, 'numEpochs': 1000, 'saveEvery': 2000, 'batchSize': 64, 'learningRate': 0.001, 'dropout': 0.9, 'clip': 5.0, 'encunit': 'lstm', 'decunit': 'lstm', 'enc_numlayer': 2, 'dec_numlayer': 2, 'maxLengthEnco': 100, 'maxLengthDeco': 101, 'temperature': 1.0, 'LMtype': 'energy', 'corpus': 'wiki2', 'server': 'dgx', 'nhead': 4, 'choose': 'BET-dm', 'norm_attn': True}
LanguageModel creation...
33586553 134.356964 m
<class 'dict'> cuda:0
23627
niters  370
2870
perplexity =  120.74602582184262 >= min_perplexity ( -1 ), saving model...
Epoch  0 loss =  3.9443955183029176 Valid perplexity =  120.74602582184262
perplexity =  100.25381865785927 >= min_perplexity ( 120.74602582184262 ), saving model...
Epoch  1 loss =  3.6301624958579604 Valid perplexity =  100.25381865785927
perplexity =  91.55112472649334 >= min_perplexity ( 100.25381865785927 ), saving model...
Epoch  2 loss =  3.5186956518405195 Valid perplexity =  91.55112472649334
perplexity =  88.0935078415772 >= min_perplexity ( 91.55112472649334 ), saving model...
Epoch  3 loss =  3.4349240203161497 Valid perplexity =  88.0935078415772
perplexity =  81.89506888212705 >= min_perplexity ( 88.0935078415772 ), saving model...
Epoch  4 loss =  3.367834001457369 Valid perplexity =  81.89506888212705
perplexity =  80.18026291617144 >= min_perplexity ( 81.89506888212705 ), saving model...
Epoch  5 loss =  3.313597861496178 Valid perplexity =  80.18026291617144
perplexity =  78.38017052297768 >= min_perplexity ( 80.18026291617144 ), saving model...
Epoch  6 loss =  3.265224496899424 Valid perplexity =  78.38017052297768
perplexity =  77.85856599697424 >= min_perplexity ( 78.38017052297768 ), saving model...
Epoch  7 loss =  3.2224848824578363 Valid perplexity =  77.85856599697424
perplexity =  75.39623024451134 >= min_perplexity ( 77.85856599697424 ), saving model...
Epoch  8 loss =  3.182045708959167 Valid perplexity =  75.39623024451134
perplexity =  73.41074653543029 >= min_perplexity ( 75.39623024451134 ), saving model...
Epoch  9 loss =  3.140436160081142 Valid perplexity =  73.41074653543029
perplexity =  71.57392793038382 >= min_perplexity ( 73.41074653543029 ), saving model...
Epoch  10 loss =  3.102007894097148 Valid perplexity =  71.57392793038382
perplexity =  71.54005513795164 >= min_perplexity ( 71.57392793038382 ), saving model...
Epoch  11 loss =  3.0656652110653955 Valid perplexity =  71.54005513795164
Epoch  12 loss =  3.0333896348605283 Valid perplexity =  71.93947871421955
perplexity =  70.42672286567243 >= min_perplexity ( 71.54005513795164 ), saving model...
Epoch  13 loss =  3.000913108039547 Valid perplexity =  70.42672286567243
perplexity =  69.84235589838441 >= min_perplexity ( 70.42672286567243 ), saving model...
Epoch  14 loss =  2.9665802001953123 Valid perplexity =  69.84235589838441
perplexity =  69.36070308941692 >= min_perplexity ( 69.84235589838441 ), saving model...
Epoch  15 loss =  2.933817402092186 Valid perplexity =  69.36070308941692
perplexity =  69.00654337254541 >= min_perplexity ( 69.36070308941692 ), saving model...
Epoch  16 loss =  2.9034541959698137 Valid perplexity =  69.00654337254541
perplexity =  67.19828106832644 >= min_perplexity ( 69.00654337254541 ), saving model...
Epoch  17 loss =  2.874550644288192 Valid perplexity =  67.19828106832644
Epoch  18 loss =  2.8438144872317443 Valid perplexity =  67.61762479224649
perplexity =  66.41267427128635 >= min_perplexity ( 67.19828106832644 ), saving model...
Epoch  19 loss =  2.8137329175665573 Valid perplexity =  66.41267427128635
perplexity =  65.82237688881014 >= min_perplexity ( 66.41267427128635 ), saving model...
Epoch  20 loss =  2.788576901925577 Valid perplexity =  65.82237688881014
perplexity =  64.5024286516016 >= min_perplexity ( 65.82237688881014 ), saving model...
Epoch  21 loss =  2.7599705433523334 Valid perplexity =  64.5024286516016
perplexity =  63.72958591051371 >= min_perplexity ( 64.5024286516016 ), saving model...
Epoch  22 loss =  2.735227538604994 Valid perplexity =  63.72958591051371
perplexity =  63.62748066155923 >= min_perplexity ( 63.72958591051371 ), saving model...
Epoch  23 loss =  2.7060653564092276 Valid perplexity =  63.62748066155923
perplexity =  62.705775544880304 >= min_perplexity ( 63.62748066155923 ), saving model...
Epoch  24 loss =  2.6786213338375093 Valid perplexity =  62.705775544880304
Epoch  25 loss =  2.65129744329968 Valid perplexity =  63.06724196807462
Epoch  26 loss =  2.630323924406155 Valid perplexity =  63.28900198589379
54m 36s (- 2021-05-17 17:28:32.043646) (10000 2702%) loss = 3.0552, CE_loss = 3.0552, VAE recon = 0.0000, KL = 0.0000, error=0.0000
Test ppl:  58.33091793939474
perplexity =  58.33091793939474 >= min_perplexity ( 62.705775544880304 ), saving model...
Epoch  27 loss =  2.603748686571379 Valid perplexity =  64.75349039245884
Epoch  28 loss =  2.580717259645462 Valid perplexity =  62.99037858013367
Epoch  29 loss =  2.5587847621054265 Valid perplexity =  62.234553437416295
Epoch  30 loss =  2.5391514280357876 Valid perplexity =  63.34622230510122
Epoch  31 loss =  2.5172933348127313 Valid perplexity =  66.80994338564665
Epoch  32 loss =  2.496945373915337 Valid perplexity =  66.45188375742632
Epoch  33 loss =  2.4752278018642118 Valid perplexity =  69.08884444106431
Epoch  34 loss =  2.4527608078879277 Valid perplexity =  73.47811460158266
Epoch  35 loss =  2.4310566182072098 Valid perplexity =  71.75164200808024
Epoch  36 loss =  2.410719659038492 Valid perplexity =  72.64438012228611
Epoch  37 loss =  2.391024067434105 Valid perplexity =  71.13549207049097
Epoch  38 loss =  2.371418340786083 Valid perplexity =  71.17136228200644
Epoch  39 loss =  2.3524077420299117 Valid perplexity =  69.09584336809652
Epoch  40 loss =  2.330560869945062 Valid perplexity =  71.84158152085011
Epoch  41 loss =  2.3081002472220242 Valid perplexity =  71.4449178680318
Epoch  42 loss =  2.285582255350577 Valid perplexity =  71.25208071776456
Epoch  43 loss =  2.2619891970544246 Valid perplexity =  72.23090031262288
Epoch  44 loss =  2.240095212008502 Valid perplexity =  69.22360924459329
Epoch  45 loss =  2.22089882799097 Valid perplexity =  70.60519583748773
Epoch  46 loss =  2.199899751914514 Valid perplexity =  72.52848741633551
Epoch  47 loss =  2.1826587151836705 Valid perplexity =  71.05182427608156
Epoch  48 loss =  2.1649689703374295 Valid perplexity =  73.51902665635805
Epoch  49 loss =  2.1454861993725234 Valid perplexity =  77.2617536651937
Epoch  50 loss =  2.1297908845785503 Valid perplexity =  75.99496941272504
Epoch  51 loss =  2.110213792807347 Valid perplexity =  78.04063657378867
Epoch  52 loss =  2.0921497457736247 Valid perplexity =  79.26192314381781
Epoch  53 loss =  2.069714541129164 Valid perplexity =  78.10072816448722
105m 40s (- 2021-05-17 18:19:35.978040) (20000 5405%) loss = 2.3300, CE_loss = 2.3300, VAE recon = 0.0000, KL = 0.0000, error=0.0000
Test ppl:  71.01762880793196
Epoch  54 loss =  2.0531926970224124 Valid perplexity =  81.86859515996595
Epoch  55 loss =  2.0375880422624384 Valid perplexity =  81.22117304743324
Epoch  56 loss =  2.023890989857751 Valid perplexity =  84.64914717325797
Epoch  57 loss =  2.0065170134241517 Valid perplexity =  87.97895442199432
Epoch  58 loss =  1.9887942941607655 Valid perplexity =  87.79889109450728
Epoch  59 loss =  1.9737783123512527 Valid perplexity =  88.56001842767931
Epoch  60 loss =  1.957079960848834 Valid perplexity =  90.41164527924056
Epoch  61 loss =  1.9416327014162733 Valid perplexity =  91.4563742833574
Epoch  62 loss =  1.926114277581911 Valid perplexity =  96.88624252326791
Epoch  63 loss =  1.9062048373995601 Valid perplexity =  96.63316354924704
Epoch  64 loss =  1.8913131270859693 Valid perplexity =  101.44391035921826
Epoch  65 loss =  1.876710996112308 Valid perplexity =  104.79684777082629
Epoch  66 loss =  1.8641948107126596 Valid perplexity =  101.56287852399574
Epoch  67 loss =  1.8502823363284806 Valid perplexity =  98.64020625970934
Epoch  68 loss =  1.835458081638491 Valid perplexity =  97.57107954524271
Epoch  69 loss =  1.8203337600102296 Valid perplexity =  95.92104207629963
Epoch  70 loss =  1.8080720597827757 Valid perplexity =  96.95438260726937
Epoch  71 loss =  1.795156976097339 Valid perplexity =  97.90788669029149
Epoch  72 loss =  1.7839036062762543 Valid perplexity =  99.53541959108533
Epoch  73 loss =  1.7738065091339317 Valid perplexity =  98.55962452900381
Epoch  74 loss =  1.7688953853136784 Valid perplexity =  103.63666847842212
Epoch  75 loss =  1.7550964025226798 Valid perplexity =  109.5735110526678
Epoch  76 loss =  1.7420082828483066 Valid perplexity =  107.41814987713914
Epoch  77 loss =  1.725251771872108 Valid perplexity =  107.05756803376514
Epoch  78 loss =  1.7165622537200516 Valid perplexity =  111.44884615960743
Epoch  79 loss =  1.7050043554724874 Valid perplexity =  111.16556224294098
Epoch  80 loss =  1.6930371253877072 Valid perplexity =  110.95361662956878
156m 31s (- 2021-05-17 19:10:27.548063) (30000 8108%) loss = 1.8589, CE_loss = 1.8589, VAE recon = 0.0000, KL = 0.0000, error=0.0000
Test ppl:  100.76094434439531
Epoch  81 loss =  1.6807263725512736 Valid perplexity =  112.70790399229803
Epoch  82 loss =  1.6707934601081385 Valid perplexity =  112.19349021941665
Epoch  83 loss =  1.6613174093736185 Valid perplexity =  116.02713195125773
Epoch  84 loss =  1.653999137395137 Valid perplexity =  119.07096442847205
Epoch  85 loss =  1.6442848418210003 Valid perplexity =  117.58768493132192
Epoch  86 loss =  1.6367566280268333 Valid perplexity =  121.33798641046462
Epoch  87 loss =  1.621889538781063 Valid perplexity =  124.90037292708655
Epoch  88 loss =  1.611432223706632 Valid perplexity =  129.1459035767086
Epoch  89 loss =  1.600927380855019 Valid perplexity =  128.61621276296592
Epoch  90 loss =  1.5895407625952283 Valid perplexity =  133.73865853955854
Epoch  91 loss =  1.5799345385383916 Valid perplexity =  136.63983031499572
